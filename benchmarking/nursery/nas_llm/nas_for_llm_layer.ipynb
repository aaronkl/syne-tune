{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Neural Architecture Search for Large Language Models\n",
    "\n",
    "\n",
    "This notebook shows how to use neural architecture search (NAS) to compress a large language model fine-tuned on some target task.\n",
    "Our NAS approach consists of two steps:\n",
    "- We first fine-tune the pre-trained model on the target task, by weight-sharing based NAS training strategies. The idea is to treat the pre-trained model as a 'super-network' that contains a large, but finite set of sub-networks. To avoid that sub-networks co-adapt we vmodify the fine-tuning the super-netwoa\n",
    "- In the second step, we use multi-objective search to find a set of sub-networks that optimally trade-off between parameter count and validation error on the target task.\n",
    "\n",
    "At the end we can plot the so-called Pareto set of architecture and select the final model that gives us the right trade-off between model size and validation error.\n",
    "\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "- So far we only support the BERT and GPT2 model family\n",
    "- For now we use Syne Tune for the multi-objective search. In the future we will use AMT, which allows us to distribute the search across multiple SageMaker training jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Install requirements\n",
    "\n",
    "Before we get started, we have to install all requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    default_data_collator,\n",
    "    TrainingArguments,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "from training import train_supernetwork\n",
    "from search import multi_objective_search\n",
    "from parse_model import get_final_model\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "We define different hyperparameters for our model and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n",
    "task_name = 'rte'\n",
    "model_type = 'bert-base-cased'\n",
    "output_dir = 'nas_output_dir'\n",
    "max_seq_length = 128\n",
    "per_device_train_batch_size = 8\n",
    "per_device_eval_batch_size = 8\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Dataset and Evaluation Metric\n",
    "\n",
    "We load the RTE dataset from the GLUE benchmarking suite via the dataset library from HuggingFace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\n",
    "    \"glue\", task_name\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"glue\", task_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This follows the standard Huggingface code from this example: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "\n",
    "if model_type.startswith(\"gpt2\"):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Preprocessing the raw_datasets\n",
    "sentence1_key, sentence2_key = task_to_keys[task_name]\n",
    "\n",
    "# Padding strategy\n",
    "padding = \"max_length\"\n",
    "\n",
    "max_seq_length = min(max_seq_length, tokenizer.model_max_length)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    args = (\n",
    "        (examples[sentence1_key],)\n",
    "        if sentence2_key is None\n",
    "        else (examples[sentence1_key], examples[sentence2_key])\n",
    "    )\n",
    "    result = tokenizer(\n",
    "        *args, padding=padding, max_length=max_seq_length, truncation=True\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "raw_datasets = raw_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "label_list = raw_datasets[\"train\"].features[\"label\"].names\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split Dataset in Training / Validation\n",
    "\n",
    "We need an extra validation set to evaluate different sub-networks during the multi-objective search. We split the training dataset from GLUE into a extra training / validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = raw_datasets[\"train\"]\n",
    "test_dataset = raw_datasets[\n",
    "    \"validation_matched\" if task_name == \"mnli\" else \"validation\"\n",
    "]\n",
    "\n",
    "train_dataset = train_dataset.remove_columns([\"idx\"])\n",
    "test_dataset = test_dataset.remove_columns([\"idx\"])\n",
    "\n",
    "split = train_dataset.train_test_split(\n",
    "    train_size=0.7, seed=0\n",
    ")  # fix seed to make results reproducible\n",
    "valid_dataset = split[\"test\"]\n",
    "\n",
    "\n",
    "data_collator = default_data_collator\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=per_device_train_batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=per_device_eval_batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_type,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=task_name,\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_type,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "\n",
    "if model_type.startswith(\"gpt2\"):\n",
    "    model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train weight-sharing based Super-Network\n",
    "\n",
    "We now fine-tune our pre-training network, i.e super-network. To control the training we can use the TrainingArguments of the HuggingFace transformer library. We can pass additional arguments to specify if our dataset is regression or not (determine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=output_dir)\n",
    "training_args.use_accelerate = False # set this to True to distribute training on multiple GPUs\n",
    "training_args.is_regression = False  # set this to True if your dataset is a regression dataset, for example STSB\n",
    "training_args.save_strategy = \"epoch\"\n",
    "training_args.log_dir = '.log_dir'\n",
    "training_args.seed = seed\n",
    "train_supernetwork(model, train_dataloader, eval_dataloader, metric, training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Multi-objective search for sub-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metric_name = 'accuracy'\n",
    "training_args.num_samples = 5\n",
    "pareto_set = multi_objective_search(model, eval_dataloader, metric, metric_name, training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_params_original_model = sum(\n",
    "            p.numel() for p in model.parameters() if p.requires_grad\n",
    "        )\n",
    "plt.axvline(n_params_original_model, color='black', linestyle='--')\n",
    "\n",
    "plt.scatter(pareto_set['params'], pareto_set['error'], marker='o', s=80,\n",
    "            facecolors='none', edgecolors='C0', linewidth=2, label='Pareto front')\n",
    "plt.xlabel('number of parameters')\n",
    "plt.ylabel('validation error')\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.grid(linewidth='1', alpha=0.4, which=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Select Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "architecture_definition = pareto_set['configs'][0]\n",
    "new_model = get_final_model(original_model=model, architecture_definition=architecture_definition)\n",
    "\n",
    "n_params_new_model = sum(\n",
    "            p.numel() for p in new_model.parameters() if p.requires_grad\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
